{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8e4638-7bcb-42ed-b757-44d5b3a0f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from random import randint\n",
    "import copy\n",
    "import json\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cProfile\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "x_mouse = None\n",
    "y_mouse = None\n",
    "old_x_mouse = None\n",
    "old_y_mouse = None\n",
    "\n",
    "\n",
    "def feature_match(image_a:np.ndarray, image_b: np.ndarray, features:int = 5000, lowe_ratio:float = 0.3, visualization:bool = 0):\n",
    "    assert 0 < lowe_ratio <=1, \"David Lowe's racio must be between 0 and 1\"\n",
    "    sift_detector = cv2.SIFT_create(nfeatures=features)\n",
    "    # Sift features  -----------------------\n",
    "    imga_key_points, imga_descriptors = sift_detector.detectAndCompute(image_a, None)\n",
    "    imgb_key_points, imgb_descriptors = sift_detector.detectAndCompute(image_b, None)\n",
    "    # Match the keypoints\n",
    "    index_params = dict(algorithm = 1, trees = 15)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann_matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    two_best_matches = flann_matcher.knnMatch(imgb_descriptors, imga_descriptors, k=2)\n",
    "    # Create a list of matches\n",
    "    matches = []\n",
    "    for match_idx, match in enumerate(two_best_matches):\n",
    "        best_match = match[0] # to get the cv2.DMatch from the tuple [match = (cv2.DMatch)]\n",
    "        second_match = match[1]\n",
    "        # David Lowe's ratio\n",
    "        if best_match.distance < lowe_ratio * second_match.distance: # this is a robust match, keep it\n",
    "            matches.append(best_match) # create a list to show with drawMatches\n",
    "    points1 = np.float32([imga_key_points[m.trainIdx].pt for m in matches])\n",
    "    points2 = np.float32([imgb_key_points[m.queryIdx].pt for m in matches])\n",
    "    if visualization:\n",
    "        concatenated_image = np.concatenate((image_a, image_b), axis=1)\n",
    "        concatenated_image = cv2.cvtColor(concatenated_image,cv2.COLOR_GRAY2RGB)\n",
    "        for i in range(len(points1)):\n",
    "            cv2.line(concatenated_image, np.asarray(points1[i], dtype=int), tuple(map(sum, zip(np.asarray(points2[i], dtype=int), (image_a.shape[1], 0)))), (randint(0,255), randint(0,255), randint(0,255)), 1)\n",
    "        cv2.imshow('Linked Points', concatenated_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    return points1, points2\n",
    "\n",
    "def calibrate_cameras(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2):\n",
    "    # Find the essential matrix\n",
    "    E, mask = cv2.findEssentialMat(points1, points2, cameraMatrix1)\n",
    "    F, mask = cv2.findFundamentalMat(points1, points2)\n",
    "    # Recover pose\n",
    "    _, R, t, _ = cv2.recoverPose(E, points1, points2, cameraMatrix1)\n",
    "    # print(f\"Rotation: \\n{R} \\nTranslation: \\n{t}\")\n",
    "    # Create projection matrices\n",
    "    P1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    P2 = np.hstack((R, t))\n",
    "    # Apply the camera intrinsics\n",
    "    P1 = cameraMatrix1 @ P1\n",
    "    P2 = cameraMatrix2 @ P2\n",
    "    # return P1, P2\n",
    "    # print(P1)\n",
    "    # print('################################')\n",
    "    # print(P2)\n",
    "    return R, t, F, P1, P2\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6f7c55-74ca-4d07-b753-c20eca89246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_point(img1, img2, point, epiline, window_size=5, l_ratio = 0.8, similarity_func=cv2.norm):\n",
    "    # Initialize best match (lowest distance)\n",
    "    best_match = None\n",
    "    second_dist = None\n",
    "    best_distance = float('inf')\n",
    "\n",
    "    a, b, c = epiline\n",
    "\n",
    "    # Iterate over each point in the epipolar line\n",
    "    for x in range(0, img2.shape[1]):\n",
    "        if b != 0:\n",
    "            y = -1*(a*x + c) / b\n",
    "            y = int(round(y))  # Ensure y is an integer for indexing\n",
    "        else:\n",
    "            continue  # If line is vertical, skip this iteration\n",
    "\n",
    "        # Check if y is within image bounds\n",
    "        if y < 0 or y >= img2.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        a1 = point[1]-window_size\n",
    "        b1 = point[1]+window_size\n",
    "        c1 = point[0]-window_size\n",
    "        d1 = point[0]+window_size\n",
    "        a2 = y-window_size\n",
    "        b2 = y+window_size\n",
    "        c2 = x-window_size\n",
    "        d2 = x+window_size\n",
    "\n",
    "        if a1 < 0 or c1 <0 or a2 <0 or c2 <0 or b1 > img1.shape[0] or d1 > img1.shape[1] or b2 > img2.shape[0] or d2 > img2.shape[1]:\n",
    "            continue\n",
    "\n",
    "        # Compute similarity measure\n",
    "        distance = similarity_func(img1[a1:b1, c1:d1],\n",
    "                                img2[a2:b2, c2:d2], cv2.NORM_L1)\n",
    "\n",
    "        # Update best match if better\n",
    "        if distance < best_distance:\n",
    "            second_dist = best_distance\n",
    "            best_distance = distance\n",
    "            best_match = (x, y)\n",
    "        #     print(f\"img1[{point[1]-window_size}:{point[1]+window_size}, {point[0]-window_size}:{point[0]+window_size}], img2[{y-window_size}:{y+window_size}, {x-window_size}:{x+window_size}\")\n",
    "    # print(f\"Best distance = {best_distance}\\nSecond = {second_dist}\")\n",
    "    if second_dist == float('inf') or second_dist is None:\n",
    "        best_match = None\n",
    "    # elif best_distance > 0.8*second_dist:\n",
    "    elif not(best_distance < l_ratio*second_dist):\n",
    "        # print('invalid')\n",
    "        best_match = None\n",
    "\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4bdedde-46f7-4bd1-8b7a-9297f43226bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_points(img1, img2, coord_array, epiline_array, window_size=5, l_ratio = 0.8, similarity_func=cv2.norm):\n",
    "    points_1 = []\n",
    "    points_2 = []\n",
    "    for idx, coord in enumerate(tqdm(coord_array)):\n",
    "        # Initialize best match (lowest distance)\n",
    "        best_match = None\n",
    "        second_dist = None\n",
    "        best_distance = float('inf')\n",
    "    \n",
    "        a, b, c = epiline_array[idx]\n",
    "    \n",
    "        # Iterate over each point in the epipolar line\n",
    "        for x in range(0, img2.shape[1]):\n",
    "            if b != 0:\n",
    "                y = -1*(a*x + c) / b\n",
    "                y = int(round(y))  # Ensure y is an integer for indexing\n",
    "            else:\n",
    "                continue  # If line is vertical, skip this iteration\n",
    "    \n",
    "            # Check if y is within image bounds\n",
    "            if y < 0 or y >= img2.shape[0]:\n",
    "                continue\n",
    "            \n",
    "            a1 = coord[1]-window_size\n",
    "            b1 = coord[1]+window_size\n",
    "            c1 = coord[0]-window_size\n",
    "            d1 = coord[0]+window_size\n",
    "            a2 = y-window_size\n",
    "            b2 = y+window_size\n",
    "            c2 = x-window_size\n",
    "            d2 = x+window_size\n",
    "    \n",
    "            if a1 < 0 or c1 <0 or a2 <0 or c2 <0 or b1 > img1.shape[0] or d1 > img1.shape[1] or b2 > img2.shape[0] or d2 > img2.shape[1]:\n",
    "                continue\n",
    "\n",
    "            # Compute similarity measure\n",
    "            distance = similarity_func(img1[a1:b1, c1:d1],\n",
    "                                    img2[a2:b2, c2:d2], cv2.NORM_L1)\n",
    "            # Update best match if better\n",
    "            if distance < best_distance:\n",
    "                second_dist = best_distance\n",
    "                best_distance = distance\n",
    "                best_match = (x, y)\n",
    "        # Remove invalids\n",
    "        if second_dist == float('inf') or second_dist is None:\n",
    "            best_match = None\n",
    "        # Filter results\n",
    "        elif not(best_distance < l_ratio*second_dist):\n",
    "            best_match = None\n",
    "        # Append valid results\n",
    "        if not(best_match is None):\n",
    "            points_1.append((coord[0], coord[1]))\n",
    "            points_2.append(best_match)\n",
    "    return points_1, points_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9087b73-c603-45e3-8986-d2b4c8b6cd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 307200/307200 [13:35<00:00, 376.64it/s]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img1_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\")\n",
    "img2_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\")\n",
    "img1_plot = copy.deepcopy(img1_back)\n",
    "img2_plot = copy.deepcopy(img2_back)\n",
    "K = np.array([[629.400223, 0.000000, 325.240410],\n",
    "            [0.000000, 627.585852, 262.311140],\n",
    "            [0.000000, 0.000000, 1.000000]])\n",
    "distCoeffs1 = None\n",
    "distCoeffs2 = None\n",
    "points1, points2 = feature_match(img1, img2, visualization=False)\n",
    "R, t, F, P1, P2 = calibrate_cameras(points1, points2, K, distCoeffs1, K, distCoeffs2)\n",
    "\n",
    "\n",
    "\n",
    "# Save data\n",
    "px_values = np.arange(img1.shape[1])\n",
    "py_values = np.arange(img1.shape[0])\n",
    "py_grid, px_grid = np.meshgrid(py_values, px_values)\n",
    "coordinate_array = np.dstack([px_grid, py_grid, np.ones_like(px_grid)]).reshape(-1, 3)\n",
    "epipolar = np.dot(F, coordinate_array.T).T\n",
    "points_1 = []\n",
    "points_2 = []\n",
    "\n",
    "best_points = find_matching_points(img1, img2, coord_array, epipolar_array, window_size=5, similarity_func=cv2.norm)\n",
    "for idx, coord in enumerate(tqdm(coordinate_array)):\n",
    "        best_point = find_matching_point(img1, img2, coord, epipolar[idx], window_size=5, similarity_func=cv2.norm)\n",
    "        if not(best_point is None):\n",
    "            points_1.append((coord[0], coord[1]))\n",
    "            points_2.append(best_point)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a63782-4d4f-4f88-9989-ddea781bfd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 307200/307200 [14:10<00:00, 361.14it/s]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img1_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\")\n",
    "img2_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\")\n",
    "img1_plot = copy.deepcopy(img1_back)\n",
    "img2_plot = copy.deepcopy(img2_back)\n",
    "K = np.array([[629.400223, 0.000000, 325.240410],\n",
    "            [0.000000, 627.585852, 262.311140],\n",
    "            [0.000000, 0.000000, 1.000000]])\n",
    "distCoeffs1 = None\n",
    "distCoeffs2 = None\n",
    "points1, points2 = feature_match(img1, img2, visualization=False)\n",
    "R, t, F, P1, P2 = calibrate_cameras(points1, points2, K, distCoeffs1, K, distCoeffs2)\n",
    "\n",
    "\n",
    "\n",
    "# Save data\n",
    "px_values = np.arange(img1.shape[1])\n",
    "py_values = np.arange(img1.shape[0])\n",
    "py_grid, px_grid = np.meshgrid(py_values, px_values)\n",
    "coordinate_array = np.dstack([px_grid, py_grid, np.ones_like(px_grid)]).reshape(-1, 3)\n",
    "epipolar = np.dot(F, coordinate_array.T).T\n",
    "points_1 = []\n",
    "points_2 = []\n",
    "\n",
    "# best_points = find_matching_points(img1, img2, coord_array, epipolar_array, window_size=5, similarity_func=cv2.norm)\n",
    "for idx in tqdm(range(0, len(coordinate_array))):\n",
    "        best_point = find_matching_point(img1, img2, coordinate_array[idx], epipolar[idx], window_size=5, similarity_func=cv2.norm)\n",
    "        if not(best_point is None):\n",
    "            points_1.append((coordinate_array[idx][0], coordinate_array[idx][1]))\n",
    "            points_2.append(best_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb988d8-d500-46d0-8c93-69063fd5722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 307200/307200 [13:55<00:00, 367.82it/s]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img1_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\")\n",
    "img2_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\")\n",
    "img1_plot = copy.deepcopy(img1_back)\n",
    "img2_plot = copy.deepcopy(img2_back)\n",
    "K = np.array([[629.400223, 0.000000, 325.240410],\n",
    "            [0.000000, 627.585852, 262.311140],\n",
    "            [0.000000, 0.000000, 1.000000]])\n",
    "distCoeffs1 = None\n",
    "distCoeffs2 = None\n",
    "points1, points2 = feature_match(img1, img2, visualization=False)\n",
    "R, t, F, P1, P2 = calibrate_cameras(points1, points2, K, distCoeffs1, K, distCoeffs2)\n",
    "\n",
    "\n",
    "\n",
    "# Save data\n",
    "px_values = np.arange(img1.shape[1])\n",
    "py_values = np.arange(img1.shape[0])\n",
    "py_grid, px_grid = np.meshgrid(py_values, px_values)\n",
    "coordinate_array = np.dstack([px_grid, py_grid, np.ones_like(px_grid)]).reshape(-1, 3)\n",
    "epipolar = np.dot(F, coordinate_array.T).T\n",
    "points_1 = []\n",
    "points_2 = []\n",
    "\n",
    "# best_points = find_matching_points(img1, img2, coord_array, epipolar_array, window_size=5, similarity_func=cv2.norm)\n",
    "for zipp in tqdm(zip(coordinate_array, epipolar), total=len(coordinate_array)):\n",
    "        best_point = find_matching_point(img1, img2, zipp[0], zipp[1], window_size=5, similarity_func=cv2.norm)\n",
    "        if not(best_point is None):\n",
    "            points_1.append((zipp[0][0], zipp[0][1]))\n",
    "            points_2.append(best_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90f831e2-b9bc-463d-80a9-2e8cd240b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coordinate_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b60bc01d-cfa4-4c7f-af3a-03b44407428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def triangulate_and_plot(P1, P2, points1, points2, img1, img2):\n",
    "    # Triangulate points\n",
    "    points_hom = cv2.triangulatePoints(P1, P2, points1.T, points2.T)\n",
    "    points_3D = points_hom / points_hom[3]\n",
    "    points_3D_np = np.array(points_3D[:3, :].T, dtype=np.float64)\n",
    "\n",
    "    # Convert points to integer for indexing\n",
    "    points1 = points1.astype(int)\n",
    "    points2 = points2.astype(int)\n",
    "\n",
    "    # Interpolate colors\n",
    "    colors1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)[points1[:, 1], points1[:, 0]]\n",
    "    colors2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)[points2[:, 1], points2[:, 0]]\n",
    "    # colors = ((colors1 + colors2) / 2).astype(np.uint8)\n",
    "    colors = colors1.astype(np.uint8)\n",
    "\n",
    "    # Create Open3D PointCloud object\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_3D_np)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors / 255)\n",
    "    \n",
    "    return pcd\n",
    "    \n",
    "def remove_isolated_points(pcd, nb_neighbors=20, std_ratio=2.0):\n",
    "    # Create a copy of the point cloud\n",
    "    pcd_clean = pcd\n",
    "\n",
    "    # Perform statistical outlier removal\n",
    "    cl, ind = pcd_clean.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "\n",
    "    # Return inlier point cloud\n",
    "    return cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea733cd-43df-46bf-b35d-e3d100d0958f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /usr/src/debug/opencv/opencv-4.9.0/modules/calib3d/src/triangulate.cpp:64: error: (-210:Unsupported format or combination of formats) Input parameters must be matrices in function 'icvTriangulatePoints'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pcd \u001b[38;5;241m=\u001b[39m \u001b[43mtriangulate_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1_back\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2_back\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mtriangulate_and_plot\u001b[0;34m(P1, P2, points1, points2, img1, img2)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtriangulate_and_plot\u001b[39m(P1, P2, points1, points2, img1, img2):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Triangulate points\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     points_hom \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriangulatePoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     points_3D \u001b[38;5;241m=\u001b[39m points_hom \u001b[38;5;241m/\u001b[39m points_hom[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      9\u001b[0m     points_3D_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(points_3D[:\u001b[38;5;241m3\u001b[39m, :]\u001b[38;5;241m.\u001b[39mT, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /usr/src/debug/opencv/opencv-4.9.0/modules/calib3d/src/triangulate.cpp:64: error: (-210:Unsupported format or combination of formats) Input parameters must be matrices in function 'icvTriangulatePoints'\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "pcd = triangulate_and_plot(P1, P2, np.array(points_1, dtype=float), np.array(points_2, dtype=float), img1_back, img2_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa29190f-d8a0-423f-b513-8ccc61256329",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd2 = remove_isolated_points(pcd, nb_neighbors=5, std_ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b3f1683-30c4-4c96-9be4-18a44c5e94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e77fb3a3-22c1-454a-b728-dda358160522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00667301, -0.01923954,  1.05517042])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epipolar_line_in_image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a7bbc2-a2d0-42f7-8d7a-f2ba5a56bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epipolar_line_in_image_2 = np.dot(F, point_in_image_1_hom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d970fd-5900-4d13-ad33-9ecc73b23647",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cols = img2.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c7857e-1acc-4631-b1f5-341f3d158d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = map(int, [0, -epipolar_line_in_image_2[2]/epipolar_line_in_image_2[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af419d-1183-43d3-a29f-5c10eeaae033",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = map(int, [cols, -(epipolar_line_in_image_2[2] + epipolar_line_in_image_2[0]*cols) / epipolar_line_in_image_2[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7804ca1c-5039-4d61-884b-724726b79965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.843845692491996"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-epipolar_line_in_image_2[2]/epipolar_line_in_image_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d097acfa-3d3e-45ad-8dd0-8919c5aab6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = int(-epipolar_line_in_image_2[2]/epipolar_line_in_image_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63170c-1099-46ff-9fe0-0f031de814fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f00a1-dbba-4840-bc68-723c1092a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = int(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4276d50-0d7e-4128-a089-00855c8a3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = int(-(epipolar_line_in_image_2[2] + epipolar_line_in_image_2[0]*cols) / epipolar_line_in_image_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7612255c-a1ea-4587-9aa7-0a011db85985",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = epipolar_line_in_image_2 = np.dot(F, point_in_image_1_hom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba810cb5-5edd-4fb8-aa46-83b2fe41f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0066730074687589135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "752f8072-1229-4e42-af7e-6800a06fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "px_max = 20  # replace with your value\n",
    "py_max = 10  # replace with your value\n",
    "\n",
    "px_values = np.arange(px_max)\n",
    "py_values = np.arange(py_max)\n",
    "\n",
    "py_grid, px_grid = np.meshgrid(py_values, px_values)\n",
    "\n",
    "coordinate_array = np.dstack([px_grid, py_grid, np.ones_like(px_grid)]).reshape(-1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8aeb0a59-b721-4696-946f-88498897920c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.72092152e-03, -1.71484882e-02,  1.00000000e+00],\n",
       "       [-6.71273983e-03, -1.71510499e-02,  1.01504279e+00],\n",
       "       [-6.70455814e-03, -1.71536117e-02,  1.03008558e+00],\n",
       "       ...,\n",
       "       [-1.27674803e-03, -1.54546490e-02,  8.65185637e+00],\n",
       "       [-1.26856634e-03, -1.54572108e-02,  8.66689915e+00],\n",
       "       [-1.26038465e-03, -1.54597726e-02,  8.68194194e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epipolar.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4769f3d4-0a52-4475-b5e3-d67004448cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 640/640 [00:00<00:00, 723.14it/s]\n"
     ]
    }
   ],
   "source": [
    "epipolar_for=[]\n",
    "for px in tqdm(range(0, img1.shape[1])):\n",
    "    for py in range(0, img1.shape[0]):\n",
    "        point_in_image_1 = (px, py)\n",
    "        # Convert the point to homogeneous coordinates.\n",
    "        point_in_image_1_hom = np.array([*point_in_image_1, 1])\n",
    "        # Compute the corresponding epipolar line in the second image.\n",
    "        a, b, c = epipolar_line_in_image_2 = np.dot(F, point_in_image_1_hom)\n",
    "        epipolar_for.append([a, b, c])\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27f249ef-a1af-4232-895a-45d1fffe581d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([639, 479,   1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37d7a6e6-40a4-4319-86fb-5ecd88a89796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00800465, -0.01992832,  1.        ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(epipolar_for[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01ecdf53-cca1-427e-8a75-d4301803aae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00800465, -0.01992832,  1.        ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epipolar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49794a9e-2aaf-41fa-83a9-d46dfa227678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([639, 479,   1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80458a94-836d-4cf5-8ed1-4dd1ab4f037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "\n",
    "# Load the shared library\n",
    "lib = ctypes.cdll.LoadLibrary('./libmatching_points.so')\n",
    "\n",
    "# Specify the argument types for the find_matching_points function\n",
    "lib.find_matching_points.argtypes = [np.ctypeslib.ndpointer(dtype=np.uint8), np.ctypeslib.ndpointer(dtype=np.uint8),  np.ctypeslib.ndpointer(dtype=np.uint16), np.ctypeslib.ndpointer(dtype=np.float64), ctypes.c_int8, ctypes.c_float]  # Fill in the rest\n",
    "\n",
    "# Call the function\n",
    "# points_1, points_2 = lib.find_matching_points(img1, img2, coord_array, epiline_array, window_size, l_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea24ece-6465-4a21-bfba-c30f35b082c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                           | 0/307200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epiline_arry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m points_1 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m points_2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 26\u001b[0m points_1, points_2 \u001b[38;5;241m=\u001b[39m \u001b[43mfind_matching_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinate_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepipolar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mfind_matching_points\u001b[0;34m(img1, img2, coord_array, epiline_array, window_size, l_ratio, similarity_func)\u001b[0m\n\u001b[1;32m      7\u001b[0m second_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m best_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m a, b, c \u001b[38;5;241m=\u001b[39m \u001b[43mepiline_arry\u001b[49m[idx]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Iterate over each point in the epipolar line\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, img2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epiline_arry' is not defined"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img1_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\")\n",
    "img2_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\")\n",
    "img1_plot = copy.deepcopy(img1_back)\n",
    "img2_plot = copy.deepcopy(img2_back)\n",
    "K = np.array([[629.400223, 0.000000, 325.240410],\n",
    "            [0.000000, 627.585852, 262.311140],\n",
    "            [0.000000, 0.000000, 1.000000]])\n",
    "distCoeffs1 = None\n",
    "distCoeffs2 = None\n",
    "points1, points2 = feature_match(img1, img2, visualization=False)\n",
    "R, t, F, P1, P2 = calibrate_cameras(points1, points2, K, distCoeffs1, K, distCoeffs2)\n",
    "\n",
    "\n",
    "\n",
    "# Save data\n",
    "px_values = np.arange(img1.shape[1])\n",
    "py_values = np.arange(img1.shape[0])\n",
    "py_grid, px_grid = np.meshgrid(py_values, px_values)\n",
    "coordinate_array = np.dstack([px_grid, py_grid, np.ones_like(px_grid)]).reshape(-1, 3)\n",
    "epipolar = np.dot(F, coordinate_array.T).T\n",
    "points_1 = []\n",
    "points_2 = []\n",
    "\n",
    "points_1, points_2 = find_matching_points(img1, img2, coordinate_array.astype(np.uint16), epipolar, 5, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "022b5b0b-290a-49df-8826-61d1353550a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4162343292.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    lib.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lib = lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "951d954a-8604-45b8-8b0f-9b49bab32f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = ctypes.CDLL('./libmatching_points.so')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84657bac-f7d0-41a6-a466-22710b25c307",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "./libmatching_points.so: undefined symbol: find_matching_points",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_matching_points\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ctypes/__init__.py:389\u001b[0m, in \u001b[0;36mCDLL.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 389\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, func)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m/usr/lib/python3.11/ctypes/__init__.py:394\u001b[0m, in \u001b[0;36mCDLL.__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_ordinal):\n\u001b[0;32m--> 394\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_FuncPtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_ordinal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_ordinal, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    396\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name_or_ordinal\n",
      "\u001b[0;31mAttributeError\u001b[0m: ./libmatching_points.so: undefined symbol: find_matching_points"
     ]
    }
   ],
   "source": [
    "lib.find_matching_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dae78d5-dbeb-49bc-8985-3649b9320d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 307200/307200 [13:46<00:00, 371.57it/s]\n",
      "  0%|                                                                                                                                                                                                           | 0/307200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_matching_point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m best_points \u001b[38;5;241m=\u001b[39m find_matching_points(img1, img2, coordinate_array, epipolar, window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, similarity_func\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mnorm)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, coord \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(coordinate_array)):\n\u001b[0;32m---> 28\u001b[0m         best_point \u001b[38;5;241m=\u001b[39m \u001b[43mfind_matching_point\u001b[49m(img1, img2, coord, epipolar[idx], window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, similarity_func\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mnorm)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(best_point \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     30\u001b[0m             points_1\u001b[38;5;241m.\u001b[39mappend((coord[\u001b[38;5;241m0\u001b[39m], coord[\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_matching_point' is not defined"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img1_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_1.png\")\n",
    "img2_back = cv2.imread(\"/home/gribeiro/PhD/phd_experiments/Camera_calibration/Feature_match/Sift/Images/astra/curved/img_0_2.png\")\n",
    "img1_plot = copy.deepcopy(img1_back)\n",
    "img2_plot = copy.deepcopy(img2_back)\n",
    "K = np.array([[629.400223, 0.000000, 325.240410],\n",
    "            [0.000000, 627.585852, 262.311140],\n",
    "            [0.000000, 0.000000, 1.000000]])\n",
    "distCoeffs1 = None\n",
    "distCoeffs2 = None\n",
    "points1, points2 = feature_match(img1, img2, visualization=False)\n",
    "R, t, F, P1, P2 = calibrate_cameras(points1, points2, K, distCoeffs1, K, distCoeffs2)\n",
    "\n",
    "\n",
    "\n",
    "# Save data\n",
    "px_values = np.arange(img1.shape[1])\n",
    "py_values = np.arange(img1.shape[0])\n",
    "py_grid, px_grid = np.meshgrid(py_values, px_values)\n",
    "coordinate_array = np.dstack([px_grid, py_grid, np.ones_like(px_grid)]).reshape(-1, 3)\n",
    "epipolar = np.dot(F, coordinate_array.T).T\n",
    "points_1 = []\n",
    "points_2 = []\n",
    "\n",
    "best_points = find_matching_points(img1, img2, coordinate_array, epipolar, window_size=5, similarity_func=cv2.norm)\n",
    "# for idx, coord in enumerate(tqdm(coordinate_array)):\n",
    "#         best_point = find_matching_point(img1, img2, coord, epipolar[idx], window_size=5, similarity_func=cv2.norm)\n",
    "#         if not(best_point is None):\n",
    "#             points_1.append((coord[0], coord[1]))\n",
    "#             points_2.append(best_point)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262a1423-c89e-445d-970c-d40d0325f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd = triangulate_and_plot(P1, P2, np.array(best_points[0], dtype=float), np.array(best_points[1], dtype=float), img1_back, img2_back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
